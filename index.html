<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" /> <!-- 手机端自适应大小 -->
  <title>WiFi Sensing and Positioning Platform</title>
  <meta name="description" content="A web dashboard and IoT demo for indoor localization using Wi-Fi, UWB, and BLE sensors." />
  <link rel="stylesheet" href="style.css" />
  
</head>
<body>

  <!-- 顶部标题（白底、细字体） -->
  <header class="hero">
    <h1>WiFi Sensing and Positioning Platform</h1>
  </header>

    <!-- 灰色introduction -->
<div class="gray-banner">
  <div class="container">
    <h2>Introduction</h2>
  </div>
</div>

  <main>
    <!-- Section 1：概览（左文） + Dashboard（右） -->
    <section class="intro-section">
     <div class="intro-container">
       <div class="intro-text">
        <p>
          Indoor navigation in complex buildings, such as hospitals and airports, has long been a technical challenge due to the limitations of GPS signals in enclosed environments. 
          Traditional positioning systems often rely on expensive hardware, complex configurations, and lack user-friendly interfaces. 
          In the 21st century, with the rapid advancement of wireless communication, artificial intelligence (AI), and augmented reality (AR) technologies, indoor positioning has entered a new era of innovation.
        </p>

        <p>
          In this work, we develop an AR-based indoor navigation system integrated with Wi-Fi positioning and AI algorithms to provide real-time and accurate indoor wayfinding services. 
          The system utilizes Wi-Fi fingerprinting enhanced by deep learning models (CNN) to achieve sub-meter positioning accuracy and transmits real-time location data to the Unity-based AR navigation platform through a Django RESTful API. 
          Users can visualize their navigation paths directly in the real-world environment via mobile devices
        </p>
         
     </div>
     <div class="intro-media">
       <img src="assets/system-structure.png" alt="System structure" />
      <!-- 或者是视频：<video controls src="assets/ecg-video.mp4"></video> -->
        <p style="text-align:center;font-size:14px;color:#777;margin-top:10px">
            Figure: The overall system structure of the indoor AR navigation platform
          </p>
</div>

    </div>
   </div>
  </section>
    
<!-- ================= Section 1.5: System Framework Overview ================= -->
<section class="intro-section" id="System-Framework">
  <div class="intro-container">
    <!-- 左侧图示 -->
    <div class="intro-media">
      <img src="assets/framework-diagram.png" alt="Wi-Fi Indoor Positioning Framework" />
      <p style="text-align:center;font-size:14px;color:#777;margin-top:10px">
        Figure: System architecture integrating Wi-Fi sensing, Django RESTful API, and Unity AR navigation.
      </p>
    </div>


    <!-- 右侧说明 -->
    <div class="intro-text">
      <h2>System Framework Overview</h2>
      <p>
        The <b>Wi-Fi Indoor Positioning Framework</b> connects three main layers: data acquisition, AI processing, and AR visualization. 
        The system captures Wi-Fi RSSI signals, processes them through a Django-based RESTful API integrated with 
        CNN and GNN deep learning models, and outputs real-time coordinates to a Unity AR navigation app.
      </p>

      <p>
        The Django backend provides endpoints such as:
      </p>
      <ul style="line-height:1.7em;">
        <li><code>/wifidata/import</code> – Upload fingerprint datasets.</li>
        <li><code>/wifidata/export</code> – Export trained data.</li>
        <li><code>/wifidata/fingerprinting</code> – Fingerprint-based prediction.</li>
        <li><code>/wifidata/cnnpredict</code> – CNN-based localization.</li>
        <li><code>/wifidata/gnnpredict</code> – GNN-based localization.</li>
      </ul>

      <p>
        This architecture ensures seamless communication between IoT data collection, AI model inference, and real-time AR navigation,
        achieving high accuracy and system scalability for complex indoor environments.
      </p>
    </div>
  </div>
</section>
<!-- ================= End Section 1.5 ================= -->
<!-- ================= Section 2: Model Performance Comparison ================= -->
<section class="intro-section" id="model-performance">
  <div class="intro-container">
    <div class="intro-text">
      <h2>Model Performance Comparison</h2>
      <p>
        To evaluate positioning accuracy, multiple algorithms including <b>KNN</b>, 
        <b>Random Forest (RF)</b>, <b>CNN</b>, and <b>GNN</b> were compared on the same Wi-Fi fingerprint dataset. 
        Deep learning models such as CNN and GNN achieve significantly lower average localization errors, 
        demonstrating the advantage of spatial feature extraction and topology awareness.
      </p>

      <table class="perf-table">
        <thead>
          <tr>
            <th>Model</th>
            <th>Average Error (m)</th>
            <th>Description</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>KNN</td>
            <td>2.30</td>
            <td>Baseline distance-based approach</td>
          </tr>
          <tr>
            <td>Random Forest</td>
            <td>1.90</td>
            <td>Enhanced fingerprinting using ensemble trees</td>
          </tr>
          <tr>
            <td>CNN</td>
            <td><b>1.78</b></td>
            <td>Deep spatial feature extraction</td>
          </tr>
          <tr>
            <td>GNN</td>
            <td><b>1.70</b></td>
            <td>Graph-based spatial relation learning</td>
          </tr>
        </tbody>
      </table>
    </div>

    <div class="intro-media">
      <canvas id="perfChart" width="500" height="350"></canvas>
      <p style="text-align:center;font-size:14px;color:#777;margin-top:10px">
        Figure: Model performance comparison showing CNN and GNN achieving the lowest errors.
      </p>
    </div>
  </div>
</section>
<!-- ================= End Section 2 ================= -->


  <!-- Section 2：WiFi Fingerprinting Localization（左图右文） -->
<section class="intro-section" id="WiFi-Fingerprint">
  <div class="intro-container">
   <!-- ✅ 左侧图片内容 -->
    <div class="intro-media">
      <img src="assets/map.png" alt="Hospital Second floor’s Navmesh map example" />
      <p style="text-align:center;font-size:14px;color:#777;margin-top:10px">
        Figure: Hospital Second floor’s Navmesh Map for WiFi Fingerprint-based Localization
      </p>
    </div>
    
    <!-- ✅ 右侧文字内容 -->
    <div class="intro-text">
      <h2>WiFi Fingerprinting Localization</h2>
      <p>
        WiFi Fingerprinting is a widely used indoor positioning method, especially suitable for GPS-denied environments like hospitals and shopping malls. 
        It collects WiFi RSSI values at various locations to build a fingerprint database. 
        The user's real-time signal is matched against the database to estimate their position.
      </p>
      
      <p>
       In this project, a Convolutional Neural Network (CNN) is applied to extract spatial features from RSSI data, achieving higher accuracy and robustness compared to traditional KNN methods. 
       The predicted location is sent via API to a Unity-based AR navigation system, enabling real-time path visualization and guidance.       
      </p>
    </div>
    </div>
</section>

    <!-- ================= Section 3: Real-time AR Navigation ================= -->
<section class="intro-section" id="ar-navigation">
  <div class="intro-container">
    
    <!-- ✅ 左侧文字内容 -->
    <div class="intro-text">
      <h2>Real-time AR Navigation</h2>
     <p>
      After accurately determining the user's position using WiFi fingerprinting and CNN models, our system transmits the location information to a Unity-based Augmented Reality (AR) mobile application via Django RESTful API.
      This application acts as a smart navigation interface, displaying virtual guides directly over the real-world environment.
     </p>

     <p>
      In the hospital scenario, the AR app overlays real-time navigation paths on the camera view of the user's smartphone. 
      Using Unity’s NavMesh and anchor system, it dynamically calculates the shortest path between the user’s current position and the desired destination such as a consultation room, pharmacy, or emergency area.
      Virtual arrows, lines, and labels are displayed on screen to guide the user intuitively through the complex indoor layout.
     </p>

     <p>
      Moreover, the system supports dynamic path updates based on the user’s movement. If the user deviates from the route, the navigation will automatically recalculate and provide a new path in real time.
      This enhances both efficiency and user experience, especially for first-time visitors, elderly patients, or emergency staff who require fast and reliable indoor guidance.
     </p>

     <p>
      This AR-based navigation platform significantly improves traditional indoor wayfinding methods by eliminating the need for paper maps, signs, or verbal instructions.
      It is particularly beneficial in large hospital environments where users may feel disoriented or stressed. By providing clear, visual, and interactive navigation, it enhances accessibility, reduces waiting times, and supports smarter healthcare operations.
     </p>
    </div>

    <!-- ✅ 右侧图片内容 -->
    <div class="intro-media">
      <img src="assets/ar-demo.png" alt="AR Navigation Interface and Unity Path" />
      <p style="text-align:center;font-size:14px;color:#777;margin-top:10px">
        Figure: Real-world AR navigation interface (left) and Unity-based path rendering (right)
      </p>
    </div>

  </div>
</section>
<!-- ================= End Section 3 ================= -->

<!-- ================= End wifi Section ================= -->

  </main>


    <footer class="footer container">
    © <span id="year"></span> The University of Sydney. All rights reserved.  Design: YIHAN WANG. 
  </footer>

  <!-- 年份脚本 -->
  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>

  <!-- ==================== Chart.js 模块 ==================== -->
  <!-- 1️⃣ 引入 Chart.js -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

  <!-- 2️⃣ 创建 Model Performance 图表 -->
  <script>
    const ctx = document.getElementById('perfChart').getContext('2d');
    new Chart(ctx, {
      type: 'line',
      data: {
        labels: ['KNN', 'Random Forest', 'CNN', 'GNN'],
        datasets: [{
          label: 'Average Error (m)',
          data: [2.3, 1.9, 1.78, 1.7],
          borderWidth: 2,
          borderColor: '#22d3ee',
          pointBackgroundColor: '#22d3ee',
          fill: false,
          tension: 0.3
        }]
      },
      options: {
        scales: {
          y: {
            beginAtZero: false,
            title: { display: true, text: 'Error (m)' }
          },
          x: {
            title: { display: true, text: 'Model' }
          }
        },
        plugins: { legend: { display: false } }
      }
    });
  </script>
</body>
</html>
